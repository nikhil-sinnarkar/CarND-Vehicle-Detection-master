{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from scipy.ndimage.measurements import label\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the SVM \n",
    "\n",
    "###### Spatial binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    spatial_features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return spatial_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Color histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), block_norm= 'L2-Hys',\n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), block_norm= 'L2-Hys',\n",
    "                       transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256),\n",
    "                        orient=9, pix_per_cell=8, cell_per_block=2, hog_channel=0):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif cspace == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)      \n",
    "        \n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        \n",
    "        # Apply color_hist() also with a color space option now\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "        \n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features)        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        \n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(np.concatenate((spatial_features, hist_features, hog_features)))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using spatial binning of: 16 and 28 histogram bins\n",
      "Feature vector length: 5652\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read in car and non-car images\n",
    "cars = glob.glob('./data/vehicles/*/*.png')\n",
    "notcars = glob.glob('./data/non-vehicles/*/*.png')\n",
    "\n",
    "# Hyper parameters that needs tuning\n",
    "spatial = 16\n",
    "histbin = 28\n",
    "orient = 12 \n",
    "pix_per_cell = 8\n",
    "cell_per_block = 4\n",
    "hog_channel = 1\n",
    "cspace = 'HSV'\n",
    "\n",
    "car_features = extract_features(cars, cspace=cspace, spatial_size=(spatial, spatial),\n",
    "                        hist_bins=histbin, hist_range=(0, 256),\n",
    "                        orient=orient, pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel)\n",
    "notcar_features = extract_features(notcars, cspace=cspace, spatial_size=(spatial, spatial),\n",
    "                        hist_bins=histbin, hist_range=(0, 256),\n",
    "                        orient=orient, pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel)\n",
    "\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=rand_state)\n",
    "    \n",
    "# Fit a per-column scaler only on the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# Apply the scaler to X_train and X_test\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "pickle.dump(X_train, open(\"X_train.p\", \"wb\"))\n",
    "pickle.dump(X_test, open(\"X_test.p\", \"wb\"))\n",
    "pickle.dump(y_train, open(\"y_train.p\", \"wb\"))\n",
    "pickle.dump(y_test, open(\"y_test.p\", \"wb\"))\n",
    "pickle.dump(X_scaler, open(\"X_scaler.p\", \"wb\"))\n",
    "\n",
    "print('Using spatial binning of:',spatial, 'and', histbin,'histogram bins')\n",
    "print('Feature vector length:', len(X_train[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.04 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9642\n",
      "My classifier predicts:  [1. 1. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "For these 10 labels:     [1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "0.0 Seconds to predict 10 labels with clf\n"
     ]
    }
   ],
   "source": [
    "# Use a linear SVC \n",
    "clf = LinearSVC()\n",
    "\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "pickle.dump(clf, open(\"clf.p\", \"wb\"))\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(clf.score(X_test, y_test), 4))\n",
    "\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My classifier predicts: ', clf.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels:    ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with clf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(image, cspace='HSV', spatial_size=(16, 16),\n",
    "                        hist_bins=28, hist_range=(0, 256),\n",
    "                        orient=12, pix_per_cell=8, cell_per_block=4, hog_channel=1):\n",
    "    # Resize the image\n",
    "#     print(\"image -\", image.shape)\n",
    "    image = cv2.resize(image,(64,64))\n",
    "    # change to png format as the training was done on png images\n",
    "    image = image.astype(np.float32)/255\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    if cspace != 'RGB':\n",
    "        if cspace == 'HSV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        elif cspace == 'LUV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "        elif cspace == 'HLS':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        elif cspace == 'YUV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        elif cspace == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(image)      \n",
    "        \n",
    "    # Apply bin_spatial() to get spatial color features\n",
    "    spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "    \n",
    "    # Apply color_hist() also with a color space option now\n",
    "    hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "      \n",
    "    # Call get_hog_features() with vis=False, feature_vec=True\n",
    "    if hog_channel == 'ALL':\n",
    "        hog_features = []\n",
    "        for channel in range(feature_image.shape[2]):\n",
    "            hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "        hog_features = np.ravel(hog_features)        \n",
    "    else:\n",
    "        hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            \n",
    "    # Append the new feature vector to the features list\n",
    "    features.append(np.concatenate((spatial_features, hist_features, hog_features)))\n",
    "    \n",
    "    features = np.array(features).astype(np.float64)\n",
    "#     print(features.shape)\n",
    "#     features = features.reshape(-1,1)\n",
    "#     print(features.shape)\n",
    "#     features = X_scaler.transform(features)\n",
    "    \n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier is trained and saved in a pickle file named \"clf.p\", I have also saved the standardScalar object in \"X_scaler.p\"\n",
    "\n",
    "now I can directly load my classifier from pickle file and use it in my pipeline.\n",
    "\n",
    "## Designing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoProcessor():\n",
    "    def __init__(self):\n",
    "        self.frame = None\n",
    "        \n",
    "    def slide_window(self, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "        # If x and/or y start/stop positions not defined, set to image size\n",
    "        if x_start_stop[0] == None:\n",
    "            x_start_stop[0] = 0\n",
    "        if x_start_stop[1] == None:\n",
    "            x_start_stop[1] = self.frame.shape[1]\n",
    "        if y_start_stop[0] == None:\n",
    "            y_start_stop[0] = 0\n",
    "        if y_start_stop[1] == None:\n",
    "            y_start_stop[1] = self.frame.shape[0]\n",
    "        # Compute the span of the region to be searched    \n",
    "        xspan = x_start_stop[1] - x_start_stop[0]\n",
    "        yspan = y_start_stop[1] - y_start_stop[0]\n",
    "        # Compute the number of pixels per step in x/y\n",
    "        nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "        ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "        # Compute the number of windows in x/y\n",
    "        nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "        ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "        nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "        ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "        # Initialize a list to append window positions to\n",
    "        window_list = []\n",
    "        # Loop through finding x and y window positions\n",
    "        # Note: you could vectorize this step, but in practice\n",
    "        # you'll be considering windows one by one with your\n",
    "        # classifier, so looping makes sense\n",
    "        for ys in range(ny_windows):\n",
    "            for xs in range(nx_windows):\n",
    "                # Calculate window position\n",
    "                startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "                endx = startx + xy_window[0]\n",
    "                starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "                endy = starty + xy_window[1]\n",
    "                # Append window position to list\n",
    "                window_list.append(((startx, starty), (endx, endy)))\n",
    "        # Return the list of windows\n",
    "        return window_list\n",
    "\n",
    "    def draw_boxes(self, bboxes, color=(0, 0, 255), thick=6):\n",
    "        # Make a copy of the image\n",
    "        draw_img = np.copy(self.frame)\n",
    "        # Iterate through the bounding boxes\n",
    "        for bbox in bboxes:\n",
    "            # Draw a rectangle given bbox coordinates\n",
    "            cv2.rectangle(draw_img, bbox[0], bbox[1], color, thick)\n",
    "        # Return the image copy with boxes drawn\n",
    "        return draw_img\n",
    "    \n",
    "    def run_classifier(self, windows_all):\n",
    "        windows_detected = []\n",
    "        # Iterate through all windows\n",
    "        for window in windows_all:\n",
    "            crop = self.frame[window[0][0]:window[1][0], window[0][1]:window[1][1]]\n",
    "            print(window[0][0],window[1][0], window[0][1],window[1][1])\n",
    "            print(crop.shape)\n",
    "            features = get_features(crop)\n",
    "#             print(clf.predict(features))\n",
    "#             if clf.predict(features) == 1:\n",
    "#                 windows_detected.append(window)\n",
    "        return windows_detected\n",
    "        \n",
    "    def pipeline(self, frame):\n",
    "#         frame = preprocess(frame)\n",
    "        self.frame = frame\n",
    "        # this function returns the xy coordinates of all the windows\n",
    "        windows_big = self.slide_window(x_start_stop=[140, None], y_start_stop=[350, 700], \n",
    "                                        xy_window=(140, 120), xy_overlap=(0.75, 0.75))\n",
    "        windows_small = self.slide_window(x_start_stop=[100, 1200], y_start_stop=[400, 550], \n",
    "                                        xy_window=(105, 88), xy_overlap=(0.75, 0))\n",
    "        windows_all = windows_big + windows_small \n",
    "#         print(windows_all)\n",
    "        # this function returns the xy coordinates of windows in which vehicle is detected\n",
    "        windows_detected = self.run_classifier(windows_all)\n",
    "        self.frame = self.draw_boxes(windows_detected, color=(0, 255, 0), thick=2)\n",
    "#         # this function returns the heatmap for the detected vehicle locations\n",
    "#         heatmap = generate_heatmap(windows_detected)\n",
    "#         # this function draws boxes around the detected vehicle\n",
    "#         draw_boxes(heatmap)\n",
    "        return self.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 280 350 470\n",
      "(140, 120, 3)\n",
      "175 315 350 470\n",
      "(140, 120, 3)\n",
      "210 350 350 470\n",
      "(140, 120, 3)\n",
      "245 385 350 470\n",
      "(140, 120, 3)\n",
      "280 420 350 470\n",
      "(140, 120, 3)\n",
      "315 455 350 470\n",
      "(140, 120, 3)\n",
      "350 490 350 470\n",
      "(140, 120, 3)\n",
      "385 525 350 470\n",
      "(140, 120, 3)\n",
      "420 560 350 470\n",
      "(140, 120, 3)\n",
      "455 595 350 470\n",
      "(140, 120, 3)\n",
      "490 630 350 470\n",
      "(140, 120, 3)\n",
      "525 665 350 470\n",
      "(140, 120, 3)\n",
      "560 700 350 470\n",
      "(140, 120, 3)\n",
      "595 735 350 470\n",
      "(125, 120, 3)\n",
      "630 770 350 470\n",
      "(90, 120, 3)\n",
      "665 805 350 470\n",
      "(55, 120, 3)\n",
      "700 840 350 470\n",
      "(20, 120, 3)\n",
      "735 875 350 470\n",
      "(0, 120, 3)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "..\\..\\..\\modules\\imgproc\\src\\imgwarp.cpp:3229: error: (-215) ssize.area() > 0 in function cv::resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-241-ca2b4fe25151>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./test_images/test3.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvideo_processor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoProcessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-240-6f12dd237da2>\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m#         print(windows_all)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m# this function returns the xy coordinates of windows in which vehicle is detected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mwindows_detected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindows_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindows_detected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthick\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;31m#         # this function returns the heatmap for the detected vehicle locations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-240-6f12dd237da2>\u001b[0m in \u001b[0;36mrun_classifier\u001b[1;34m(self, windows_all)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;31m#             print(clf.predict(features))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;31m#             if clf.predict(features) == 1:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-239-7e1f80eeb39f>\u001b[0m in \u001b[0;36mget_features\u001b[1;34m(image, cspace, spatial_size, hist_bins, hist_range, orient, pix_per_cell, cell_per_block, hog_channel)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Resize the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     print(\"image -\", image.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m# change to png format as the training was done on png images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: ..\\..\\..\\modules\\imgproc\\src\\imgwarp.cpp:3229: error: (-215) ssize.area() > 0 in function cv::resize\n"
     ]
    }
   ],
   "source": [
    "img = mpimg.imread('./test_images/test3.jpg')\n",
    "video_processor = VideoProcessor()\n",
    "img = video_processor.pipeline(img)\n",
    "f, ax = plt.subplots(1,1,figsize=(16,16))\n",
    "ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My classifier predicts:  [1.]\n",
      "For these 10 labels:     [1.]\n",
      "0.07291 Seconds to predict 10 labels with clf\n"
     ]
    }
   ],
   "source": [
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My classifier predicts: ', clf.predict(X_test[0:1]))\n",
    "print('For these',n_predict, 'labels:    ', y_test[0:1])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with clf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3552, 5652)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
